Modern scientific collaborations have opened the opportunity of solving complex problems that involve multidisciplinary expertise and large-scale computational experiments. 
These experiments comprise a sequence of processing steps, or referred as tasks, that need to be executed on selected computing platforms. 
To support this research, UM has formed the Data Intensive Computing Centre (DICC)1 to provide High Performance Computing (HPC) services to the campus community. 
 
High Performance Computing is a practise of harnessing the power of aggregated computers or supercomputer, to solve complex problems that involves massive calculation and huge volume of data. 
It is been achieved by connecting many servers/workstations via high-speed network, and managed it with a set of cluster management middleware and supporting systems. 
 
From the users perspective, a HPC cluster is like an everyday use computer, except it is way more powerful, as the calculation is taking place in many computing nodes, and run in parallel. 
Users login from their computers to the HPC cluster login node using the SSH program or web browser (e.g. via Open OnDemand portal), to submit their calculation, known as jobs.  
 
There may be different types of nodes for different types of jobs. Our HPC cluster consists of the following: 
VPN Gateway, where users establish a private connection to interact with Login Node and internal HPC resources 
Login Node, where users log in via SSH or Open OnDemand portal 
CPU compute nodes (where majority of computations will be executed) 
GPU compute nodes (for those jobs that can benefit from the massive parallel execution on Graphical Processing Unit) 
Storage nodes (where the data is been stored) 
